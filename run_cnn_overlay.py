============================

BITFILE = "cnn.bit"
DATA_FILE = "cifar_test_100.txt"

SCALE = 1024   # ap_fixed<16,6> fractional bits = 10 â†’ 2^10

# ==============================
# Load Overlay
# ==============================

print("Loading overlay...")
ol = Overlay(BITFILE)

cnn = ol.cnn_top_0

print("Overlay loaded")

# ==============================
# Allocate Buffers (int16)
# ==============================

inp = allocate(shape=(3072,), dtype=np.int16)
out = allocate(shape=(10,), dtype=np.int16)

# ==============================
# Load CIFAR Dataset
# ==============================

dataset = np.loadtxt(DATA_FILE)

labels = dataset[:, 0].astype(int)
pixels = dataset[:, 1:]

print("Dataset loaded:", pixels.shape)

# ==============================
# Inference Loop
# ==============================

correct = 0
start_time = time.time()

for i in range(len(pixels)):

    # ---- Get image ----
    img = pixels[i].reshape(3, 32, 32)

    # ---- Normalization (IMPORTANT) ----
    img = (img - 0.5) / 0.5

    # ---- Convert to fixed point ----
    inp[:] = (img.flatten() * SCALE).astype(np.int16)

    # ---- Write DDR addresses ----
    cnn.write(0x10, inp.physical_address)
    cnn.write(0x1C, out.physical_address)

    # ---- Start accelerator ----
    cnn.write(0x00, 1)

    # ---- Wait done ----
    while not (cnn.read(0x00) & 0x2):
        pass

    # ---- Convert output back to float ----
    out_float = out.astype(np.float32) / SCALE

    pred = np.argmax(out_float)

    if pred == labels[i]:
        correct += 1

    print(f"Image {i}: True={labels[i]}  Pred={pred}")

# ==============================
# Results
# ==============================

elapsed = time.time() - start_time
accuracy = correct / len(pixels) * 100

print("\n==============================")
print("Accuracy:", accuracy, "%")
print("Time:", elapsed, "seconds")
print("FPS:", len(pixels) / elapsed)
print("==============================")